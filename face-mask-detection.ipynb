{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/covid19-face-mask-data'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Specify Data Loaders for the Dog Dataset**\n\n *The code cell below write three separate data loaders for the training, validation, and test datasets of humans images (located at covid19-face-mask-data/face-mask-dataset/train, covid19-face-mask-data/face-mask-dataset/valid, and covid19-face-mask-data/face-mask-dataset/test, respectively). You may find this [documentation on custom datasets](http://pytorch.org/docs/stable/torchvision/datasets.html) to be a useful resource. If you are interested in augmenting your training and/or validation data, check out the wide variety of [transforms](http://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform)!*"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from PIL import Image\nimport torchvision.transforms as transforms\nimport torch\nimport os\nfrom torchvision import datasets\n\ndatadir = {\n\n    'train': '../input/covid19-face-mask-data/face-mask-dataset/train/',\n    'valid': '../input/covid19-face-mask-data/face-mask-dataset/validation/',\n    'test': '../input/covid19-face-mask-data/face-mask-dataset/test'\n}\n\ntrns_normalize = transforms.Normalize([0.485, 0.456, 0.406],\n                            [0.229, 0.224, 0.225])\n\ntransform_transfer = {}\ntransform_transfer['train'] = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomResizedCrop(224),\n        transforms.ToTensor(),\n        trns_normalize\n    ])\ntransform_transfer['valid'] = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        trns_normalize\n    ])\ntransform_transfer['test'] = transform_transfer['valid']\n\n# Trying out an idiom found in the pytorch docs\ndatafolder_transfer = {x: datasets.ImageFolder(datadir[x], transform=transform_transfer[x]) for x in ['train', 'valid', 'test']}\n\nbatch_size = 20\nnum_workers = 0\n\n# Trying out an idiom found in the pytorch docs\nloaders_transfer = {x: torch.utils.data.DataLoader(datafolder_transfer[x], batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True) \nfor x in ['train', 'valid', 'test']}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model Architecture**\nUse transfer learning to create a CNN to classify the face mask breed. Use the code cell below, and save your initialized model as the variable model_transfer."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\n\n## TODO: Specify model architecture \nmodel_transfer = models.vgg16(pretrained=True)\n\nfor param in model_transfer.features.parameters():\n    param.requires_grad = False\n    \n### make changes to final fully collected layers\nn_inputs = model_transfer.classifier[6].in_features\nlast_layer = nn.Linear(n_inputs, 133)\nmodel_transfer.classifier[6] = last_layer\n# check if CUDA is available\nuse_cuda = torch.cuda.is_available()\n\nif use_cuda:\n    model_transfer = model_transfer.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model_transfer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Specify Loss Function and Optimizer\nUse the next code cell to specify a loss [function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html). Save the chosen loss function as criterion_transfer, and the optimizer as optimizer_transfer below."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\ncriterion_transfer = nn.CrossEntropyLoss()\n\noptimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Validate the Model\nTrain and validate your model in the code cell below. [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath 'model_transfer.pt'."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom glob import glob\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\ndef train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    \"\"\"returns trained model\"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf \n    \n    for epoch in range(1, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        model.train()\n        torch.enable_grad()\n        for batch_idx, (data, target) in enumerate(loaders['train']):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## find the loss and update the model parameters accordingly\n            ## record the average training loss, using something like\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            # train_loss += loss.item()*data.size(0) # From cifar10_cnn_solution.py\n            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n        \n        ######################\n        # validate the model #\n        ######################\n        model.eval()\n        torch.no_grad()\n        for batch_idx, (data, target) in enumerate(loaders['valid']):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## update the average validation loss\n            output = model(data)\n            loss = criterion(output, target)\n            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n            \n        # print training/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch,\n            train_loss,\n            valid_loss\n            ))\n        \n        ## save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n            \n    # return trained model\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model\nn_epochs =4 \nmodel_transfer = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n\n# load the model that got the best validation accuracy (uncomment the line below)\nmodel_transfer.load_state_dict(torch.load('model_transfer.pt'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model_transfer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Test the Model**\nTry out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy. Ensure that your test accuracy is greater than 60%."},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(loaders, model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    model.eval()\n    for batch_idx, (data, target) in enumerate(loaders['test']):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n        100. * correct / total, correct, total))\n\n# call test function\n#test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict if a human is wearing a face mask or not  with the Model\nWrite a function that takes an image path as input and returns the mask if the man present on the image is wearing a mask  (mask, out mask) that is predicted by your model."},{"metadata":{"trusted":true},"cell_type":"code","source":"###  Write a function that takes a path to an image as input\n### and returns the dog breed that is predicted by the model.\n\ndef predict_transfer(img_path):\n    # load the image and return the predicted breed\n    img = Image.open(img_path).convert('RGB')\n    size = (224, 224) # ResNet image size requirements\n    transform_chain = transforms.Compose([\n        transforms.Resize(size),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406),\n                            (0.229, 0.224, 0.225))\n    ])\n\n    img = transform_chain(img).unsqueeze(0)\n\n    if use_cuda:\n        img = img.cuda()\n\n    model_out = model_transfer(img)\n\n    if use_cuda:\n        model_out = model_out.cpu()\n    \n    prediction = torch.argmax(model_out)\n    \n    return class_names[prediction]  # predicted class label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write your Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \ndef run_app(img_path):\n   \n    result = predict_transfer(img_path)\n    #print(result )\n    # display the image, along with bounding box\n    if result == \" mask\" :\n        print('This person is responsible, he wears his face mask!!!!!')\n    else :\n        print('This person is irresponsible, he does not wear his face mask!!!!!')\n    img = plt.imread(img_path, 3)\n    plt.imshow(img)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Your Algorithm\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Execute your algorithm from Step 6 on\n## at least 6 images on your computer.\n## Feel free to use as many code cells as needed.\n\n## suggested code, below\n\nfor file in np.array(glob(\"../input/covid19-face-mask-recognition-test-data/Covid19-face-mask-recognition-test-data/*\")):\n    run_app(file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# step7: optional integrate opencv to the project"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport cv2                                       \n%matplotlib inline \ndef run_app_with_opencv(img_path):\n    # extract pre-trained face detector\n    face_cascade = cv2.CascadeClassifier('../input/xmldoc/haarcascade_frontalface_default.xml')\n\n    # load color (BGR) image\n    img = cv2.imread(img_path)\n    # convert BGR image to grayscale\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    # find faces in image\n    faces = face_cascade.detectMultiScale(gray)\n\n    # get bounding box for each detected face\n    for (x,y,w,h) in faces:\n        # add bounding box to color image\n        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n\n    # convert BGR image to RGB for plotting\n    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    result = predict_transfer(img_path)\n    # display the image, along with bounding box\n    if result == \" mask\" :\n        print(\"This person is responsible, he wears his face mask!!!!!\" )\n    else :\n        print('This person is irresponsible, he does not wear his face mask!!!!!')\n\n    plt.imshow(cv_rgb)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Execute your algorithm from Step 6 \n## on 1 images on your computer.\n## Feel free to use as many you want.\nfor file in np.array(glob(\"../input/covid19-face-mask-recognition-test-data/Covid19-face-mask-recognition-test-data/4.jpeg\")):\n    run_app_with_opencv(file)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}